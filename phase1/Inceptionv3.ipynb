{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fc44da4-6b39-4122-b9f4-2d9d879722b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.7.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.66.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.8/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fe4db04-41d8-4392-a5a9-55e346fab952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 16:02:32.186068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 16:02:32.895334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2547d4a-0cc3-4852-b17b-959156ba1468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1O4YR4UBatOLnaP4gMHbmFw7UJvhhxFwq&export=download\n",
      "From (redirected): https://drive.google.com/uc?id=1O4YR4UBatOLnaP4gMHbmFw7UJvhhxFwq&export=download&confirm=t&uuid=48e17287-8b19-42a8-8195-bde9e1d2af2a\n",
      "To: /jupyter/train_data.zip\n",
      "100%|██████████| 173M/173M [00:30<00:00, 5.72MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'train_data.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/uc?id=1O4YR4UBatOLnaP4gMHbmFw7UJvhhxFwq&export=download'\n",
    "gdown.download(url,quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb8aa11c-f75f-41c7-90dc-7e728ea6698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patool in /usr/local/lib/python3.8/dist-packages (1.12)\n",
      "patool: Extracting train_data.zip ...\n",
      "patool: ... train_data.zip extracted to `train'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install patool\n",
    "import patoolib\n",
    "patoolib.extract_archive(\"train_data.zip\" , outdir = \"train\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f1d837a-bc78-41ff-b63e-5bd87c0adf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "# 1. Data Preparation: Organize your dataset into subdirectories.\n",
    "\n",
    "train_data_dir = \"train/train_data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5fcd820-3fdb-44d5-ab4a-f274da75b11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/qubvel/classification_models.git\n",
      "  Cloning https://github.com/qubvel/classification_models.git to /tmp/pip-req-build-0e9l1huz\n",
      "  Running command git clone -q https://github.com/qubvel/classification_models.git /tmp/pip-req-build-0e9l1huz\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied (use --upgrade to upgrade): image-classifiers==1.0.0 from git+https://github.com/qubvel/classification_models.git in /usr/local/lib/python3.8/dist-packages\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from image-classifiers==1.0.0) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.8/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (1.24.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from keras_applications<=1.0.8,>=1.0.7->image-classifiers==1.0.0) (3.9.0)\n",
      "Building wheels for collected packages: image-classifiers\n",
      "  Building wheel for image-classifiers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for image-classifiers: filename=image_classifiers-1.0.0-py3-none-any.whl size=20031 sha256=4bb0579e46c745665641b17ac1ee6c722a52e565295040b4bcce732a1aaf97b5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sbrddu68/wheels/77/23/ad/afd2caf2877de1a21565559524b6435e5396579c14207062f3\n",
      "Successfully built image-classifiers\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/qubvel/classification_models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5650b073-7373-45c9-a47a-fbd58578820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7994 images belonging to 10 classes.\n",
      "Found 1996 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from classification_models.keras import Classifiers\n",
    "inceptionv3, preprocess_input = Classifiers.get('inceptionv3')\n",
    "\n",
    "# Define image dimensions\n",
    "image_height, image_width = 299, 299\n",
    "\n",
    "# Define the number of classes (labels)\n",
    "num_classes = 10\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 64\n",
    "\n",
    "'''\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # Use ResNet50's preprocessing\n",
    "    validation_split = 0.2,\n",
    "    rescale = 1./255\n",
    ")\n",
    "'''\n",
    "#Create an instance of ImageDataGenerator with preprocessing\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "     preprocessing_function=preprocess_input,\n",
    "     width_shift_range = 0.2,\n",
    "     height_shift_range = 0.2,\n",
    "     validation_split = 0.2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create data generators for training and validation\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11ea96c7-75f9-4d4c-bacb-cdd05e47ae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam ,SGD ,RMSprop\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras import regularizers\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46cbec88-4c8c-4e47-998e-f0142b9d71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    return lr * math.exp(-0.1)\n",
    "\n",
    "from keras import regularizers\n",
    "model = inceptionv3(weights='imagenet', include_top=False, input_shape=(image_height, image_width, 3))\n",
    "\n",
    "\n",
    "for layer in model.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(num_classes, activation='softmax' , kernel_regularizer=regularizers.l2(0.02))(x)\n",
    "\n",
    "\n",
    "new_model = keras.models.Model(inputs=model.input , outputs = predictions)\n",
    "\n",
    "alpha = 0.01  # Learning rate\n",
    "beta_1 = 0.9   # First moment decay (similar to momentum in SGD)\n",
    "\n",
    "new_model.compile(optimizer = Adam(learning_rate=alpha, beta_1=beta_1) , loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True , min_delta=0.001),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf._keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor= 0.2 ,patience=5, min_lr=0.01 , min_delta=0.01)\n",
    "]\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e6594-0f86-40ac-8432-14decf06ea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 16:03:51.459995: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-11-12 16:03:51.993499: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-12 16:03:52.458136: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-12 16:03:53.386157: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb19d1519e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-12 16:03:53.386183: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2023-11-12 16:03:53.390172: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-12 16:03:53.445994: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-11-12 16:03:53.509086: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 47/125 [==========>...................] - ETA: 1:03 - loss: 2.9779 - acc: 0.3444"
     ]
    }
   ],
   "source": [
    "new_model.fit(\n",
    "    train_generator,\n",
    "    epochs=100,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[my_callbacks,lr_scheduler]\n",
    ")\n",
    "#model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959554c5-8703-491d-8095-de688cfc98ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
